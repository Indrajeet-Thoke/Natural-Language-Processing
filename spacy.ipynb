{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e561944",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#load the English Language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#Example text\n",
    "text = \"Apple is looking at buying U.k. startup for $1 billion\"\n",
    "#process the text\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c56e0ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple is looking at buying U.k. startup for $1 billion"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7263b442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name  Entities, Phrases, and concepts :\n",
      "Apple           ORG                 0          5\n",
      "$1 billion      MONEY              44         54\n"
     ]
    }
   ],
   "source": [
    "#print the named entities in the text\n",
    "print(\"Name  Entities, Phrases, and concepts :\")\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:15} {ent.label_:10} {ent.start_char:10} {ent.end_char:10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ea4297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text Summarization using Spacy\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"data science and ai  & gen ai has a greate career ahead\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5423b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data science and ai  & gen ai has a greate career ahead"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94306449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "science\n",
      "and\n",
      "ai\n",
      " \n",
      "&\n",
      "gen\n",
      "ai\n",
      "has\n",
      "a\n",
      "greate\n",
      "career\n",
      "ahead\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data science and ai  & gen ai has a greate career ahead"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaff298c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOUN\n",
      "NOUN\n",
      "CCONJ\n",
      "VERB\n",
      "SPACE\n",
      "CCONJ\n",
      "PROPN\n",
      "PROPN\n",
      "VERB\n",
      "DET\n",
      "ADJ\n",
      "NOUN\n",
      "ADV\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa1a074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : NOUN\n",
      "science : NOUN\n",
      "and : CCONJ\n",
      "ai : VERB\n",
      "  : SPACE\n",
      "& : CCONJ\n",
      "gen : PROPN\n",
      "ai : PROPN\n",
      "has : VERB\n",
      "a : DET\n",
      "greate : ADJ\n",
      "career : NOUN\n",
      "ahead : ADV\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, \":\", token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : NOUN --> data compound\n",
      "science : NOUN --> science nsubj\n",
      "and : CCONJ --> and cc\n",
      "ai : VERB --> ai conj\n",
      "  : SPACE -->   dep\n",
      "& : CCONJ --> & cc\n",
      "gen : PROPN --> gen conj\n",
      "ai : PROPN --> ai conj\n",
      "has : VERB --> have ROOT\n",
      "a : DET --> a det\n",
      "greate : ADJ --> greate amod\n",
      "career : NOUN --> career dobj\n",
      "ahead : ADV --> ahead advmod\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, \":\", token.pos_,\"-->\", token.lemma_, token.dep_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a2cbc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data data NOUN NN compound 13110060611322374290 True False\n",
      "science science NOUN NN nsubj 13110060611322374290 True False\n",
      "and and CCONJ CC cc 4088098365541558500 True True\n",
      "ai ai VERB VB conj 4370460163704169311 True False\n",
      "    SPACE _SP dep 8532415787641010193 False False\n",
      "& & CCONJ CC cc 15473034735919704609 False False\n",
      "gen gen PROPN NNP conj 4088098365541558500 True False\n",
      "ai ai PROPN NNP conj 4370460163704169311 True False\n",
      "has have VERB VBZ ROOT 4088098365541558500 True True\n",
      "a a DET DT det 11123243248953317070 True True\n",
      "greate greate ADJ JJ amod 13110060611322374290 True False\n",
      "career career NOUN NN dobj 13110060611322374290 True False\n",
      "ahead ahead ADV RB advmod 13110060611322374290 True False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e38d0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
    "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
    "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\nAn example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\nImage collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5f24cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "977345a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thereby',\n",
       " 'along',\n",
       " 'herein',\n",
       " 'n‘t',\n",
       " 'himself',\n",
       " 'nine',\n",
       " 'does',\n",
       " 'most',\n",
       " 'wherein',\n",
       " 'also',\n",
       " 'could',\n",
       " 'them',\n",
       " 'the',\n",
       " 'around',\n",
       " 'off',\n",
       " 'name',\n",
       " 'such',\n",
       " 'your',\n",
       " 'anyone',\n",
       " 'elsewhere',\n",
       " 'whose',\n",
       " 'are',\n",
       " 'you',\n",
       " 'then',\n",
       " 'in',\n",
       " 'ten',\n",
       " \"'d\",\n",
       " 'since',\n",
       " 'anyhow',\n",
       " 'enough',\n",
       " 'fifty',\n",
       " 'myself',\n",
       " 'ours',\n",
       " 'their',\n",
       " 'as',\n",
       " 'from',\n",
       " 'thereupon',\n",
       " 'none',\n",
       " 'besides',\n",
       " 'many',\n",
       " 'just',\n",
       " 'but',\n",
       " 'on',\n",
       " 'with',\n",
       " 'other',\n",
       " 'about',\n",
       " 'beyond',\n",
       " 'hundred',\n",
       " 'out',\n",
       " 'into',\n",
       " '‘ll',\n",
       " 'made',\n",
       " 'upon',\n",
       " 'for',\n",
       " 'hereby',\n",
       " 'whole',\n",
       " 'be',\n",
       " '‘ve',\n",
       " 'side',\n",
       " 'again',\n",
       " 'against',\n",
       " 'when',\n",
       " 'within',\n",
       " 'even',\n",
       " 'between',\n",
       " 'will',\n",
       " 'another',\n",
       " 'seemed',\n",
       " 'during',\n",
       " 'twenty',\n",
       " \"'m\",\n",
       " '‘re',\n",
       " 'amount',\n",
       " 'six',\n",
       " 'mine',\n",
       " 'while',\n",
       " 'everyone',\n",
       " 'because',\n",
       " 'up',\n",
       " 'seem',\n",
       " 'put',\n",
       " 'becomes',\n",
       " 'how',\n",
       " 'therein',\n",
       " 'was',\n",
       " 'except',\n",
       " 'an',\n",
       " 'whoever',\n",
       " 'our',\n",
       " 'twelve',\n",
       " 'without',\n",
       " 'towards',\n",
       " 'where',\n",
       " 'and',\n",
       " 'must',\n",
       " 'afterwards',\n",
       " 'becoming',\n",
       " \"'re\",\n",
       " 'hereafter',\n",
       " 'further',\n",
       " 'or',\n",
       " 'than',\n",
       " 'keep',\n",
       " 'via',\n",
       " 'meanwhile',\n",
       " 'namely',\n",
       " 'him',\n",
       " 'part',\n",
       " 'cannot',\n",
       " 'forty',\n",
       " 'might',\n",
       " 'something',\n",
       " 'beforehand',\n",
       " 'due',\n",
       " 'have',\n",
       " 'would',\n",
       " 'whence',\n",
       " 'whither',\n",
       " 'four',\n",
       " 'front',\n",
       " 'several',\n",
       " 'above',\n",
       " 'eleven',\n",
       " 'used',\n",
       " 'mostly',\n",
       " 'full',\n",
       " 'others',\n",
       " 'thence',\n",
       " 'if',\n",
       " 'once',\n",
       " 'take',\n",
       " 'did',\n",
       " 'ever',\n",
       " 'here',\n",
       " 'been',\n",
       " 'latterly',\n",
       " 'yet',\n",
       " 'else',\n",
       " 'nor',\n",
       " 'say',\n",
       " 'that',\n",
       " 'see',\n",
       " 'therefore',\n",
       " 'across',\n",
       " '‘d',\n",
       " 'whom',\n",
       " 'go',\n",
       " 'each',\n",
       " 'do',\n",
       " 'last',\n",
       " 'seeming',\n",
       " 'now',\n",
       " 'before',\n",
       " 'never',\n",
       " 'behind',\n",
       " 'any',\n",
       " 'however',\n",
       " 'move',\n",
       " 'who',\n",
       " 'became',\n",
       " '’s',\n",
       " 'those',\n",
       " 'well',\n",
       " 'every',\n",
       " 'two',\n",
       " 'indeed',\n",
       " 'top',\n",
       " 'unless',\n",
       " 'sixty',\n",
       " 'always',\n",
       " 'get',\n",
       " 'done',\n",
       " 'amongst',\n",
       " 'third',\n",
       " 'doing',\n",
       " 'make',\n",
       " 'whereupon',\n",
       " 'nevertheless',\n",
       " 'anything',\n",
       " 'my',\n",
       " 'everywhere',\n",
       " 'hers',\n",
       " 'these',\n",
       " '‘s',\n",
       " 'either',\n",
       " 'less',\n",
       " 'nobody',\n",
       " 'this',\n",
       " 'yourselves',\n",
       " 'may',\n",
       " 'anywhere',\n",
       " 'his',\n",
       " 'through',\n",
       " 'one',\n",
       " 'why',\n",
       " 'a',\n",
       " 'over',\n",
       " 'sometimes',\n",
       " 'latter',\n",
       " 'moreover',\n",
       " 'we',\n",
       " \"'s\",\n",
       " 'same',\n",
       " 'whereafter',\n",
       " 'thru',\n",
       " 'hence',\n",
       " 'noone',\n",
       " \"n't\",\n",
       " 'back',\n",
       " 'somewhere',\n",
       " 'too',\n",
       " 'show',\n",
       " 'all',\n",
       " 'what',\n",
       " 'please',\n",
       " 'already',\n",
       " \"'ll\",\n",
       " 'regarding',\n",
       " 'whereas',\n",
       " 'though',\n",
       " 'until',\n",
       " 'there',\n",
       " 'very',\n",
       " 'down',\n",
       " 'she',\n",
       " 'throughout',\n",
       " 'three',\n",
       " 'herself',\n",
       " 'first',\n",
       " 'under',\n",
       " 'empty',\n",
       " 'whether',\n",
       " 'whenever',\n",
       " 'serious',\n",
       " 'nothing',\n",
       " 'yours',\n",
       " 'which',\n",
       " '’d',\n",
       " 'ca',\n",
       " 'anyway',\n",
       " 'ourselves',\n",
       " 'it',\n",
       " 'thereafter',\n",
       " 'wherever',\n",
       " 'thus',\n",
       " 'neither',\n",
       " 'were',\n",
       " 'onto',\n",
       " 'eight',\n",
       " \"'ve\",\n",
       " 'quite',\n",
       " 'whereby',\n",
       " 're',\n",
       " 'often',\n",
       " 'really',\n",
       " 'should',\n",
       " '’m',\n",
       " 'am',\n",
       " 'still',\n",
       " 'almost',\n",
       " 'next',\n",
       " 'together',\n",
       " 'sometime',\n",
       " 'formerly',\n",
       " 'much',\n",
       " 'me',\n",
       " 'after',\n",
       " 'below',\n",
       " 'yourself',\n",
       " 'otherwise',\n",
       " 'perhaps',\n",
       " 'not',\n",
       " 'various',\n",
       " 'few',\n",
       " '’ll',\n",
       " 'least',\n",
       " 'to',\n",
       " 'her',\n",
       " 'nowhere',\n",
       " '’re',\n",
       " 'itself',\n",
       " 'so',\n",
       " 'call',\n",
       " 'former',\n",
       " 'bottom',\n",
       " 'per',\n",
       " 'of',\n",
       " 'everything',\n",
       " 'only',\n",
       " 'n’t',\n",
       " 'by',\n",
       " 'has',\n",
       " 'whatever',\n",
       " 'is',\n",
       " 'give',\n",
       " 'he',\n",
       " 'being',\n",
       " '’ve',\n",
       " 'i',\n",
       " 'beside',\n",
       " 'fifteen',\n",
       " 'more',\n",
       " 'own',\n",
       " 'both',\n",
       " 'they',\n",
       " 'its',\n",
       " 'toward',\n",
       " 'using',\n",
       " 'no',\n",
       " 'some',\n",
       " 'had',\n",
       " 'can',\n",
       " 'seems',\n",
       " 'become',\n",
       " 'somehow',\n",
       " 'at',\n",
       " 'themselves',\n",
       " 'rather',\n",
       " 'hereupon',\n",
       " 'among',\n",
       " '‘m',\n",
       " 'although',\n",
       " 'alone',\n",
       " 'us',\n",
       " 'someone',\n",
       " 'five']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cacbee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "285a077e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['thereby',\n",
       " 'along',\n",
       " 'herein',\n",
       " 'n‘t',\n",
       " 'himself',\n",
       " 'nine',\n",
       " 'does',\n",
       " 'most',\n",
       " 'wherein',\n",
       " 'also',\n",
       " 'could',\n",
       " 'them',\n",
       " 'the',\n",
       " 'around',\n",
       " 'off',\n",
       " 'name',\n",
       " 'such',\n",
       " 'your',\n",
       " 'anyone',\n",
       " 'elsewhere',\n",
       " 'whose',\n",
       " 'are',\n",
       " 'you',\n",
       " 'then',\n",
       " 'in',\n",
       " 'ten',\n",
       " \"'d\",\n",
       " 'since',\n",
       " 'anyhow',\n",
       " 'enough',\n",
       " 'fifty',\n",
       " 'myself',\n",
       " 'ours',\n",
       " 'their',\n",
       " 'as',\n",
       " 'from',\n",
       " 'thereupon',\n",
       " 'none',\n",
       " 'besides',\n",
       " 'many',\n",
       " 'just',\n",
       " 'but',\n",
       " 'on',\n",
       " 'with',\n",
       " 'other',\n",
       " 'about',\n",
       " 'beyond',\n",
       " 'hundred',\n",
       " 'out',\n",
       " 'into',\n",
       " '‘ll',\n",
       " 'made',\n",
       " 'upon',\n",
       " 'for',\n",
       " 'hereby',\n",
       " 'whole',\n",
       " 'be',\n",
       " '‘ve',\n",
       " 'side',\n",
       " 'again',\n",
       " 'against',\n",
       " 'when',\n",
       " 'within',\n",
       " 'even',\n",
       " 'between',\n",
       " 'will',\n",
       " 'another',\n",
       " 'seemed',\n",
       " 'during',\n",
       " 'twenty',\n",
       " \"'m\",\n",
       " '‘re',\n",
       " 'amount',\n",
       " 'six',\n",
       " 'mine',\n",
       " 'while',\n",
       " 'everyone',\n",
       " 'because',\n",
       " 'up',\n",
       " 'seem',\n",
       " 'put',\n",
       " 'becomes',\n",
       " 'how',\n",
       " 'therein',\n",
       " 'was',\n",
       " 'except',\n",
       " 'an',\n",
       " 'whoever',\n",
       " 'our',\n",
       " 'twelve',\n",
       " 'without',\n",
       " 'towards',\n",
       " 'where',\n",
       " 'and',\n",
       " 'must',\n",
       " 'afterwards',\n",
       " 'becoming',\n",
       " \"'re\",\n",
       " 'hereafter',\n",
       " 'further',\n",
       " 'or',\n",
       " 'than',\n",
       " 'keep',\n",
       " 'via',\n",
       " 'meanwhile',\n",
       " 'namely',\n",
       " 'him',\n",
       " 'part',\n",
       " 'cannot',\n",
       " 'forty',\n",
       " 'might',\n",
       " 'something',\n",
       " 'beforehand',\n",
       " 'due',\n",
       " 'have',\n",
       " 'would',\n",
       " 'whence',\n",
       " 'whither',\n",
       " 'four',\n",
       " 'front',\n",
       " 'several',\n",
       " 'above',\n",
       " 'eleven',\n",
       " 'used',\n",
       " 'mostly',\n",
       " 'full',\n",
       " 'others',\n",
       " 'thence',\n",
       " 'if',\n",
       " 'once',\n",
       " 'take',\n",
       " 'did',\n",
       " 'ever',\n",
       " 'here',\n",
       " 'been',\n",
       " 'latterly',\n",
       " 'yet',\n",
       " 'else',\n",
       " 'nor',\n",
       " 'say',\n",
       " 'that',\n",
       " 'see',\n",
       " 'therefore',\n",
       " 'across',\n",
       " '‘d',\n",
       " 'whom',\n",
       " 'go',\n",
       " 'each',\n",
       " 'do',\n",
       " 'last',\n",
       " 'seeming',\n",
       " 'now',\n",
       " 'before',\n",
       " 'never',\n",
       " 'behind',\n",
       " 'any',\n",
       " 'however',\n",
       " 'move',\n",
       " 'who',\n",
       " 'became',\n",
       " '’s',\n",
       " 'those',\n",
       " 'well',\n",
       " 'every',\n",
       " 'two',\n",
       " 'indeed',\n",
       " 'top',\n",
       " 'unless',\n",
       " 'sixty',\n",
       " 'always',\n",
       " 'get',\n",
       " 'done',\n",
       " 'amongst',\n",
       " 'third',\n",
       " 'doing',\n",
       " 'make',\n",
       " 'whereupon',\n",
       " 'nevertheless',\n",
       " 'anything',\n",
       " 'my',\n",
       " 'everywhere',\n",
       " 'hers',\n",
       " 'these',\n",
       " '‘s',\n",
       " 'either',\n",
       " 'less',\n",
       " 'nobody',\n",
       " 'this',\n",
       " 'yourselves',\n",
       " 'may',\n",
       " 'anywhere',\n",
       " 'his',\n",
       " 'through',\n",
       " 'one',\n",
       " 'why',\n",
       " 'a',\n",
       " 'over',\n",
       " 'sometimes',\n",
       " 'latter',\n",
       " 'moreover',\n",
       " 'we',\n",
       " \"'s\",\n",
       " 'same',\n",
       " 'whereafter',\n",
       " 'thru',\n",
       " 'hence',\n",
       " 'noone',\n",
       " \"n't\",\n",
       " 'back',\n",
       " 'somewhere',\n",
       " 'too',\n",
       " 'show',\n",
       " 'all',\n",
       " 'what',\n",
       " 'please',\n",
       " 'already',\n",
       " \"'ll\",\n",
       " 'regarding',\n",
       " 'whereas',\n",
       " 'though',\n",
       " 'until',\n",
       " 'there',\n",
       " 'very',\n",
       " 'down',\n",
       " 'she',\n",
       " 'throughout',\n",
       " 'three',\n",
       " 'herself',\n",
       " 'first',\n",
       " 'under',\n",
       " 'empty',\n",
       " 'whether',\n",
       " 'whenever',\n",
       " 'serious',\n",
       " 'nothing',\n",
       " 'yours',\n",
       " 'which',\n",
       " '’d',\n",
       " 'ca',\n",
       " 'anyway',\n",
       " 'ourselves',\n",
       " 'it',\n",
       " 'thereafter',\n",
       " 'wherever',\n",
       " 'thus',\n",
       " 'neither',\n",
       " 'were',\n",
       " 'onto',\n",
       " 'eight',\n",
       " \"'ve\",\n",
       " 'quite',\n",
       " 'whereby',\n",
       " 're',\n",
       " 'often',\n",
       " 'really',\n",
       " 'should',\n",
       " '’m',\n",
       " 'am',\n",
       " 'still',\n",
       " 'almost',\n",
       " 'next',\n",
       " 'together',\n",
       " 'sometime',\n",
       " 'formerly',\n",
       " 'much',\n",
       " 'me',\n",
       " 'after',\n",
       " 'below',\n",
       " 'yourself',\n",
       " 'otherwise',\n",
       " 'perhaps',\n",
       " 'not',\n",
       " 'various',\n",
       " 'few',\n",
       " '’ll',\n",
       " 'least',\n",
       " 'to',\n",
       " 'her',\n",
       " 'nowhere',\n",
       " '’re',\n",
       " 'itself',\n",
       " 'so',\n",
       " 'call',\n",
       " 'former',\n",
       " 'bottom',\n",
       " 'per',\n",
       " 'of',\n",
       " 'everything',\n",
       " 'only',\n",
       " 'n’t',\n",
       " 'by',\n",
       " 'has',\n",
       " 'whatever',\n",
       " 'is',\n",
       " 'give',\n",
       " 'he',\n",
       " 'being',\n",
       " '’ve',\n",
       " 'i',\n",
       " 'beside',\n",
       " 'fifteen',\n",
       " 'more',\n",
       " 'own',\n",
       " 'both',\n",
       " 'they',\n",
       " 'its',\n",
       " 'toward',\n",
       " 'using',\n",
       " 'no',\n",
       " 'some',\n",
       " 'had',\n",
       " 'can',\n",
       " 'seems',\n",
       " 'become',\n",
       " 'somehow',\n",
       " 'at',\n",
       " 'themselves',\n",
       " 'rather',\n",
       " 'hereupon',\n",
       " 'among',\n",
       " '‘m',\n",
       " 'although',\n",
       " 'alone',\n",
       " 'us',\n",
       " 'someone',\n",
       " 'five']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\n",
       "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document. Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is called multi-document summarization. A related application is summarizing news articles. Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\n",
       "Image collection summarization is another application example of automatic summarization. It consists in selecting a representative set of images from a larger set of images.[4] A summary in this context is useful to show the most representative images of results in an image collection exploration system. Video summarization is a related domain, where the system automatically creates a trailer of a long video. This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There',\n",
       " 'are',\n",
       " 'broadly',\n",
       " 'two',\n",
       " 'types',\n",
       " 'of',\n",
       " 'extractive',\n",
       " 'summarization',\n",
       " 'tasks',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'what',\n",
       " 'the',\n",
       " 'summarization',\n",
       " 'program',\n",
       " 'focuses',\n",
       " 'on',\n",
       " '.',\n",
       " 'The',\n",
       " 'first',\n",
       " 'is',\n",
       " 'generic',\n",
       " 'summarization',\n",
       " ',',\n",
       " 'which',\n",
       " 'focuses',\n",
       " 'on',\n",
       " 'obtaining',\n",
       " 'a',\n",
       " 'generic',\n",
       " 'summary',\n",
       " 'or',\n",
       " 'abstract',\n",
       " 'of',\n",
       " 'the',\n",
       " 'collection',\n",
       " '(',\n",
       " 'whether',\n",
       " 'documents',\n",
       " ',',\n",
       " 'or',\n",
       " 'sets',\n",
       " 'of',\n",
       " 'images',\n",
       " ',',\n",
       " 'or',\n",
       " 'videos',\n",
       " ',',\n",
       " 'news',\n",
       " 'stories',\n",
       " 'etc',\n",
       " '.',\n",
       " ')',\n",
       " '.',\n",
       " 'The',\n",
       " 'second',\n",
       " 'is',\n",
       " 'query',\n",
       " 'relevant',\n",
       " 'summarization',\n",
       " ',',\n",
       " 'sometimes',\n",
       " 'called',\n",
       " 'query',\n",
       " '-',\n",
       " 'based',\n",
       " 'summarization',\n",
       " ',',\n",
       " 'which',\n",
       " 'summarizes',\n",
       " 'objects',\n",
       " 'specific',\n",
       " 'to',\n",
       " 'a',\n",
       " 'query',\n",
       " '.',\n",
       " 'Summarization',\n",
       " 'systems',\n",
       " 'are',\n",
       " 'able',\n",
       " 'to',\n",
       " 'create',\n",
       " 'both',\n",
       " 'query',\n",
       " 'relevant',\n",
       " 'text',\n",
       " 'summaries',\n",
       " 'and',\n",
       " 'generic',\n",
       " 'machine',\n",
       " '-',\n",
       " 'generated',\n",
       " 'summaries',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'what',\n",
       " 'the',\n",
       " 'user',\n",
       " 'needs',\n",
       " '.',\n",
       " '\\n',\n",
       " 'An',\n",
       " 'example',\n",
       " 'of',\n",
       " 'a',\n",
       " 'summarization',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'document',\n",
       " 'summarization',\n",
       " ',',\n",
       " 'which',\n",
       " 'attempts',\n",
       " 'to',\n",
       " 'automatically',\n",
       " 'produce',\n",
       " 'an',\n",
       " 'abstract',\n",
       " 'from',\n",
       " 'a',\n",
       " 'given',\n",
       " 'document',\n",
       " '.',\n",
       " 'Sometimes',\n",
       " 'one',\n",
       " 'might',\n",
       " 'be',\n",
       " 'interested',\n",
       " 'in',\n",
       " 'generating',\n",
       " 'a',\n",
       " 'summary',\n",
       " 'from',\n",
       " 'a',\n",
       " 'single',\n",
       " 'source',\n",
       " 'document',\n",
       " ',',\n",
       " 'while',\n",
       " 'others',\n",
       " 'can',\n",
       " 'use',\n",
       " 'multiple',\n",
       " 'source',\n",
       " 'documents',\n",
       " '(',\n",
       " 'for',\n",
       " 'example',\n",
       " ',',\n",
       " 'a',\n",
       " 'cluster',\n",
       " 'of',\n",
       " 'articles',\n",
       " 'on',\n",
       " 'the',\n",
       " 'same',\n",
       " 'topic',\n",
       " ')',\n",
       " '.',\n",
       " 'This',\n",
       " 'problem',\n",
       " 'is',\n",
       " 'called',\n",
       " 'multi',\n",
       " '-',\n",
       " 'document',\n",
       " 'summarization',\n",
       " '.',\n",
       " 'A',\n",
       " 'related',\n",
       " 'application',\n",
       " 'is',\n",
       " 'summarizing',\n",
       " 'news',\n",
       " 'articles',\n",
       " '.',\n",
       " 'Imagine',\n",
       " 'a',\n",
       " 'system',\n",
       " ',',\n",
       " 'which',\n",
       " 'automatically',\n",
       " 'pulls',\n",
       " 'together',\n",
       " 'news',\n",
       " 'articles',\n",
       " 'on',\n",
       " 'a',\n",
       " 'given',\n",
       " 'topic',\n",
       " '(',\n",
       " 'from',\n",
       " 'the',\n",
       " 'web',\n",
       " ')',\n",
       " ',',\n",
       " 'and',\n",
       " 'concisely',\n",
       " 'represents',\n",
       " 'the',\n",
       " 'latest',\n",
       " 'news',\n",
       " 'as',\n",
       " 'a',\n",
       " 'summary',\n",
       " '.',\n",
       " '\\n',\n",
       " 'Image',\n",
       " 'collection',\n",
       " 'summarization',\n",
       " 'is',\n",
       " 'another',\n",
       " 'application',\n",
       " 'example',\n",
       " 'of',\n",
       " 'automatic',\n",
       " 'summarization',\n",
       " '.',\n",
       " 'It',\n",
       " 'consists',\n",
       " 'in',\n",
       " 'selecting',\n",
       " 'a',\n",
       " 'representative',\n",
       " 'set',\n",
       " 'of',\n",
       " 'images',\n",
       " 'from',\n",
       " 'a',\n",
       " 'larger',\n",
       " 'set',\n",
       " 'of',\n",
       " 'images.[4',\n",
       " ']',\n",
       " 'A',\n",
       " 'summary',\n",
       " 'in',\n",
       " 'this',\n",
       " 'context',\n",
       " 'is',\n",
       " 'useful',\n",
       " 'to',\n",
       " 'show',\n",
       " 'the',\n",
       " 'most',\n",
       " 'representative',\n",
       " 'images',\n",
       " 'of',\n",
       " 'results',\n",
       " 'in',\n",
       " 'an',\n",
       " 'image',\n",
       " 'collection',\n",
       " 'exploration',\n",
       " 'system',\n",
       " '.',\n",
       " 'Video',\n",
       " 'summarization',\n",
       " 'is',\n",
       " 'a',\n",
       " 'related',\n",
       " 'domain',\n",
       " ',',\n",
       " 'where',\n",
       " 'the',\n",
       " 'system',\n",
       " 'automatically',\n",
       " 'creates',\n",
       " 'a',\n",
       " 'trailer',\n",
       " 'of',\n",
       " 'a',\n",
       " 'long',\n",
       " 'video',\n",
       " '.',\n",
       " 'This',\n",
       " 'also',\n",
       " 'has',\n",
       " 'applications',\n",
       " 'in',\n",
       " 'consumer',\n",
       " 'or',\n",
       " 'personal',\n",
       " 'videos',\n",
       " ',',\n",
       " 'where',\n",
       " 'one',\n",
       " 'might',\n",
       " 'want',\n",
       " 'to',\n",
       " 'skip',\n",
       " 'the',\n",
       " 'boring',\n",
       " 'or',\n",
       " 'repetitive',\n",
       " 'actions',\n",
       " '.',\n",
       " 'Similarly',\n",
       " ',',\n",
       " 'in',\n",
       " 'surveillance',\n",
       " 'videos',\n",
       " ',',\n",
       " 'one',\n",
       " 'would',\n",
       " 'want',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'important',\n",
       " 'and',\n",
       " 'suspicious',\n",
       " 'activity',\n",
       " ',',\n",
       " 'while',\n",
       " 'ignoring',\n",
       " 'all',\n",
       " 'the',\n",
       " 'boring',\n",
       " 'and',\n",
       " 'redundant',\n",
       " 'frames',\n",
       " 'captured']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets get the tokens from the text\n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83d0b6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to calculate the word frequencies and then we will use those frequencies to get the weighted scores for each sentence\n",
    "word_frequencies = {}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56b7b8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'broadly': 1,\n",
       " 'types': 1,\n",
       " 'extractive': 1,\n",
       " 'summarization': 11,\n",
       " 'tasks': 1,\n",
       " 'depending': 2,\n",
       " 'program': 1,\n",
       " 'focuses': 2,\n",
       " 'generic': 3,\n",
       " 'obtaining': 1,\n",
       " 'summary': 4,\n",
       " 'abstract': 2,\n",
       " 'collection': 3,\n",
       " 'documents': 2,\n",
       " 'sets': 1,\n",
       " 'images': 3,\n",
       " 'videos': 3,\n",
       " 'news': 4,\n",
       " 'stories': 1,\n",
       " 'etc': 1,\n",
       " 'second': 1,\n",
       " 'query': 4,\n",
       " 'relevant': 2,\n",
       " 'called': 2,\n",
       " 'based': 1,\n",
       " 'summarizes': 1,\n",
       " 'objects': 1,\n",
       " 'specific': 1,\n",
       " 'Summarization': 1,\n",
       " 'systems': 1,\n",
       " 'able': 1,\n",
       " 'create': 1,\n",
       " 'text': 1,\n",
       " 'summaries': 2,\n",
       " 'machine': 1,\n",
       " 'generated': 1,\n",
       " 'user': 1,\n",
       " 'needs': 1,\n",
       " '\\n': 2,\n",
       " 'example': 3,\n",
       " 'problem': 2,\n",
       " 'document': 4,\n",
       " 'attempts': 1,\n",
       " 'automatically': 3,\n",
       " 'produce': 1,\n",
       " 'given': 2,\n",
       " 'interested': 1,\n",
       " 'generating': 1,\n",
       " 'single': 1,\n",
       " 'source': 2,\n",
       " 'use': 1,\n",
       " 'multiple': 1,\n",
       " 'cluster': 1,\n",
       " 'articles': 3,\n",
       " 'topic': 2,\n",
       " 'multi': 1,\n",
       " 'related': 2,\n",
       " 'application': 2,\n",
       " 'summarizing': 1,\n",
       " 'Imagine': 1,\n",
       " 'system': 3,\n",
       " 'pulls': 1,\n",
       " 'web': 1,\n",
       " 'concisely': 1,\n",
       " 'represents': 1,\n",
       " 'latest': 1,\n",
       " 'Image': 1,\n",
       " 'automatic': 1,\n",
       " 'consists': 1,\n",
       " 'selecting': 1,\n",
       " 'representative': 2,\n",
       " 'set': 2,\n",
       " 'larger': 1,\n",
       " 'images.[4': 1,\n",
       " 'context': 1,\n",
       " 'useful': 1,\n",
       " 'results': 1,\n",
       " 'image': 1,\n",
       " 'exploration': 1,\n",
       " 'Video': 1,\n",
       " 'domain': 1,\n",
       " 'creates': 1,\n",
       " 'trailer': 1,\n",
       " 'long': 1,\n",
       " 'video': 1,\n",
       " 'applications': 1,\n",
       " 'consumer': 1,\n",
       " 'personal': 1,\n",
       " 'want': 2,\n",
       " 'skip': 1,\n",
       " 'boring': 2,\n",
       " 'repetitive': 1,\n",
       " 'actions': 1,\n",
       " 'Similarly': 1,\n",
       " 'surveillance': 1,\n",
       " 'extract': 1,\n",
       " 'important': 1,\n",
       " 'suspicious': 1,\n",
       " 'activity': 1,\n",
       " 'ignoring': 1,\n",
       " 'redundant': 1,\n",
       " 'frames': 1,\n",
       " 'captured': 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency = max(word_frequencies.values())\n",
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e6abd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get normalized frequency we will divide each frequency by the maximum frequency\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = word_frequencies[word]/max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e908d354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'broadly': 0.09090909090909091,\n",
       " 'types': 0.09090909090909091,\n",
       " 'extractive': 0.09090909090909091,\n",
       " 'summarization': 1.0,\n",
       " 'tasks': 0.09090909090909091,\n",
       " 'depending': 0.18181818181818182,\n",
       " 'program': 0.09090909090909091,\n",
       " 'focuses': 0.18181818181818182,\n",
       " 'generic': 0.2727272727272727,\n",
       " 'obtaining': 0.09090909090909091,\n",
       " 'summary': 0.36363636363636365,\n",
       " 'abstract': 0.18181818181818182,\n",
       " 'collection': 0.2727272727272727,\n",
       " 'documents': 0.18181818181818182,\n",
       " 'sets': 0.09090909090909091,\n",
       " 'images': 0.2727272727272727,\n",
       " 'videos': 0.2727272727272727,\n",
       " 'news': 0.36363636363636365,\n",
       " 'stories': 0.09090909090909091,\n",
       " 'etc': 0.09090909090909091,\n",
       " 'second': 0.09090909090909091,\n",
       " 'query': 0.36363636363636365,\n",
       " 'relevant': 0.18181818181818182,\n",
       " 'called': 0.18181818181818182,\n",
       " 'based': 0.09090909090909091,\n",
       " 'summarizes': 0.09090909090909091,\n",
       " 'objects': 0.09090909090909091,\n",
       " 'specific': 0.09090909090909091,\n",
       " 'Summarization': 0.09090909090909091,\n",
       " 'systems': 0.09090909090909091,\n",
       " 'able': 0.09090909090909091,\n",
       " 'create': 0.09090909090909091,\n",
       " 'text': 0.09090909090909091,\n",
       " 'summaries': 0.18181818181818182,\n",
       " 'machine': 0.09090909090909091,\n",
       " 'generated': 0.09090909090909091,\n",
       " 'user': 0.09090909090909091,\n",
       " 'needs': 0.09090909090909091,\n",
       " '\\n': 0.18181818181818182,\n",
       " 'example': 0.2727272727272727,\n",
       " 'problem': 0.18181818181818182,\n",
       " 'document': 0.36363636363636365,\n",
       " 'attempts': 0.09090909090909091,\n",
       " 'automatically': 0.2727272727272727,\n",
       " 'produce': 0.09090909090909091,\n",
       " 'given': 0.18181818181818182,\n",
       " 'interested': 0.09090909090909091,\n",
       " 'generating': 0.09090909090909091,\n",
       " 'single': 0.09090909090909091,\n",
       " 'source': 0.18181818181818182,\n",
       " 'use': 0.09090909090909091,\n",
       " 'multiple': 0.09090909090909091,\n",
       " 'cluster': 0.09090909090909091,\n",
       " 'articles': 0.2727272727272727,\n",
       " 'topic': 0.18181818181818182,\n",
       " 'multi': 0.09090909090909091,\n",
       " 'related': 0.18181818181818182,\n",
       " 'application': 0.18181818181818182,\n",
       " 'summarizing': 0.09090909090909091,\n",
       " 'Imagine': 0.09090909090909091,\n",
       " 'system': 0.2727272727272727,\n",
       " 'pulls': 0.09090909090909091,\n",
       " 'web': 0.09090909090909091,\n",
       " 'concisely': 0.09090909090909091,\n",
       " 'represents': 0.09090909090909091,\n",
       " 'latest': 0.09090909090909091,\n",
       " 'Image': 0.09090909090909091,\n",
       " 'automatic': 0.09090909090909091,\n",
       " 'consists': 0.09090909090909091,\n",
       " 'selecting': 0.09090909090909091,\n",
       " 'representative': 0.18181818181818182,\n",
       " 'set': 0.18181818181818182,\n",
       " 'larger': 0.09090909090909091,\n",
       " 'images.[4': 0.09090909090909091,\n",
       " 'context': 0.09090909090909091,\n",
       " 'useful': 0.09090909090909091,\n",
       " 'results': 0.09090909090909091,\n",
       " 'image': 0.09090909090909091,\n",
       " 'exploration': 0.09090909090909091,\n",
       " 'Video': 0.09090909090909091,\n",
       " 'domain': 0.09090909090909091,\n",
       " 'creates': 0.09090909090909091,\n",
       " 'trailer': 0.09090909090909091,\n",
       " 'long': 0.09090909090909091,\n",
       " 'video': 0.09090909090909091,\n",
       " 'applications': 0.09090909090909091,\n",
       " 'consumer': 0.09090909090909091,\n",
       " 'personal': 0.09090909090909091,\n",
       " 'want': 0.18181818181818182,\n",
       " 'skip': 0.09090909090909091,\n",
       " 'boring': 0.18181818181818182,\n",
       " 'repetitive': 0.09090909090909091,\n",
       " 'actions': 0.09090909090909091,\n",
       " 'Similarly': 0.09090909090909091,\n",
       " 'surveillance': 0.09090909090909091,\n",
       " 'extract': 0.09090909090909091,\n",
       " 'important': 0.09090909090909091,\n",
       " 'suspicious': 0.09090909090909091,\n",
       " 'activity': 0.09090909090909091,\n",
       " 'ignoring': 0.09090909090909091,\n",
       " 'redundant': 0.09090909090909091,\n",
       " 'frames': 0.09090909090909091,\n",
       " 'captured': 0.09090909090909091}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6dc43603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).,\n",
       " This problem is called multi-document summarization.,\n",
       " A related application is summarizing news articles.,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.,\n",
       " Image collection summarization is another application example of automatic summarization.,\n",
       " It consists in selecting a representative set of images from a larger set of images.[4],\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_tokens = [sent for sent in doc.sents]\n",
    "sentence_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40f5788b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22d04030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are gong to calculate the sentence scores, to calculate the sentence scores we will add the word frequencies of each word in the sentence\n",
    "sentence_scores = {}\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.text.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "900c8f02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{There are broadly two types of extractive summarization tasks depending on what the summarization program focuses on.: 2.818181818181818,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).: 3.9999999999999987,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 3.909090909090909,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.: 3.2727272727272716,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.: 3.9999999999999996,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while others can use multiple source documents (for example, a cluster of articles on the same topic).: 2.545454545454545,\n",
       " This problem is called multi-document summarization.: 1.8181818181818183,\n",
       " A related application is summarizing news articles.: 1.0909090909090908,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.: 2.9090909090909087,\n",
       " Image collection summarization is another application example of automatic summarization.: 2.909090909090909,\n",
       " It consists in selecting a representative set of images from a larger set of images.[4]: 1.1818181818181817,\n",
       " A summary in this context is useful to show the most representative images of results in an image collection exploration system.: 1.818181818181818,\n",
       " Video summarization is a related domain, where the system automatically creates a trailer of a long video.: 2.2727272727272725,\n",
       " This also has applications in consumer or personal videos, where one might want to skip the boring or repetitive actions.: 1.1818181818181817,\n",
       " Similarly, in surveillance videos, one would want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured: 1.4545454545454544}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9394590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fab04a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_length = int(len(sentence_tokens)*0.4)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c1b79d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.,\n",
       " Image collection summarization is another application example of automatic summarization.,\n",
       " Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we have to select maximum 40% of the sentences based on their scores\n",
    "summary = nlargest(select_length, sentence_scores, key=sentence_scores.get)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b63db46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An example of a summarization problem is document summarization, which attempts to automatically produce an abstract from a given document.',\n",
       " 'The first is generic summarization, which focuses on obtaining a generic summary or abstract of the collection (whether documents, or sets of images, or videos, news stories etc.).',\n",
       " 'The second is query relevant summarization, sometimes called query-based summarization, which summarizes objects specific to a query.',\n",
       " 'Summarization systems are able to create both query relevant text summaries and generic machine-generated summaries depending on what the user needs.\\n',\n",
       " 'Image collection summarization is another application example of automatic summarization.',\n",
       " 'Imagine a system, which automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news as a summary.\\n']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if i need to combine these top 3 sentence then\n",
    "final_summary = [word.text for word in summary]\n",
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566a21e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c70d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23a93b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc6939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257c10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44facf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f81671c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f64a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a9942c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
